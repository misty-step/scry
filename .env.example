# Environment Variables for Scry
# Copy this file to .env.local and fill in your actual values
# Never commit real API keys or secrets to the repository!

# ==============================================================================
# CRITICAL: Vercel vs Convex Environment Variables
# ==============================================================================
# Vercel and Convex maintain SEPARATE environment variable systems!
# Variables must be set in BOTH places where indicated below.
#
# Local Development:
#   - This .env.local file is used by BOTH Next.js AND Convex (via npx convex dev)
#
# Production:
#   - Vercel variables: Set via `vercel env add` or Vercel dashboard
#   - Convex variables: Set via `npx convex env set --prod` or Convex dashboard
#
# See CLAUDE.md for detailed setup instructions.
# ==============================================================================

# ------------------------------------------------------------------------------
# FRONTEND VARIABLES (Vercel only in production)
# ------------------------------------------------------------------------------

# Sentry Observability (frontend + backend error tracking)
#
# ⭐ RECOMMENDED SETUP (2025 Best Practice):
#   1. Install Sentry Vercel Integration: https://vercel.com/integrations/sentry
#      - Auto-creates SENTRY_AUTH_TOKEN and NEXT_PUBLIC_SENTRY_DSN in Vercel
#      - Eliminates release ID mismatch issues
#      - Automatically links deployments to Sentry releases
#   2. Copy DSN to .env.local for development:
#      NEXT_PUBLIC_SENTRY_DSN=https://...@o0.ingest.sentry.io/0
#   3. For Convex backend errors: Set SENTRY_DSN in Convex dashboard
#      npx convex env set SENTRY_DSN "https://...@o0.ingest.sentry.io/0" --prod
#   4. Done! Source maps upload automatically, no manual token needed.
#
# Alternative: Manual Setup (if not using Vercel Integration)
#   - Get DSN from: https://sentry.io → Settings → Client Keys
#   - Get auth token from: https://sentry.io/settings/account/api/auth-tokens/
#   - Token needs 'project:releases' and 'project:write' scopes
#   - Set SENTRY_AUTH_TOKEN, SENTRY_ORG, SENTRY_PROJECT in Vercel
#
# DSN Configuration:
#   - NEXT_PUBLIC_SENTRY_DSN: Client-side errors (browser, exposed in bundle)
#   - SENTRY_DSN: Server-side errors (API routes, middleware, edge functions)
#   - Usually both use the same DSN (from Sentry → Settings → Client Keys)
NEXT_PUBLIC_SENTRY_DSN=https://examplePublicKey@o0.ingest.sentry.io/0
SENTRY_DSN=https://exampleServerKey@o0.ingest.sentry.io/0
# SENTRY_AUTH_TOKEN=your-sentry-auth-token       # Auto-set by Vercel Integration
# SENTRY_ORG=your-sentry-org                     # Auto-set by Vercel Integration
# SENTRY_PROJECT=your-sentry-project             # Auto-set by Vercel Integration
#
# CLI/API Access (for script-based alert configuration):
# Get from: https://sentry.io/settings/account/api/auth-tokens/
# Required scopes: project:write, alerts:write
# Used by: scripts/configure-sentry-alerts.sh
# SENTRY_API_TOKEN=sntrys_xxx
#
# Performance & Replay Sampling (controls cost vs visibility):
# Defaults: traces=10%, routine replays=0%, error replays=100%
# Session Replay captures user interactions before errors for debugging
# Adjust if approaching Sentry free tier limit (5k errors/month = ~166/day)
# SENTRY_TRACES_SAMPLE_RATE=0.1                  # Performance traces (0.0-1.0)
# SENTRY_REPLAYS_SESSION_SAMPLE_RATE=0.05        # Session replays for normal sessions (5%)
# SENTRY_REPLAYS_ON_ERROR_SAMPLE_RATE=1.0        # Session replays when errors occur (100%)
#
# Troubleshooting:
#   - "Minified stack traces": Vercel Integration not installed or source maps not uploading
#   - "Errors not appearing": Check DSN matches Sentry project, verify environment
#   - "CSP violations": Sentry uses /monitoring tunnel route (configured in next.config.ts)
#   - "High quota usage": Lower sample rates or add ignore rules in Sentry dashboard
#   - "Replay not working": Check REPLAYS_SESSION_SAMPLE_RATE > 0 or errors triggering

# Convex Backend URL
# Dev: https://amicable-lobster-935.convex.cloud
# Prod: https://uncommon-axolotl-639.convex.cloud
# Where to set: Vercel (production), .env.local (dev)
NEXT_PUBLIC_CONVEX_URL=https://your-convex-instance.convex.cloud

# Clerk Authentication (frontend)
# Get from: https://dashboard.clerk.com
# Where to set: Vercel (production), .env.local (dev)
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_test_...
CLERK_SECRET_KEY=sk_test_...
CLERK_WEBHOOK_SECRET=whsec_...

# Clerk routing - dedicated sign-in/sign-up pages
NEXT_PUBLIC_CLERK_SIGN_IN_URL=/sign-in
NEXT_PUBLIC_CLERK_SIGN_UP_URL=/sign-up

# Convex Deploy Key (for Vercel build process)
# Get from: https://dashboard.convex.dev → Settings → Deploy Keys
# Where to set: Vercel (production only)
# CONVEX_DEPLOY_KEY=prod:uncommon-axolotl-639|...

# ------------------------------------------------------------------------------
# BACKEND VARIABLES (Convex only in production)
# ------------------------------------------------------------------------------

# --------------
# AI PROVIDER CONFIGURATION
# --------------

# OpenRouter API Key
# Get from: https://openrouter.ai/keys
# Where to set: Convex (production), .env.local (dev)
# Used by: convex/lib/aiProviders.ts
# Provides access to 150+ models via single API
OPENROUTER_API_KEY=sk-or-v1-...

# AI Model ID (OpenRouter format)
# Examples:
#   - google/gemini-3-flash-preview (Gemini 3 Pro with extended thinking - newest)
#   - google/gemini-2.5-pro-preview-0827 (Gemini 2.5 Pro)
#   - anthropic/claude-3.5-sonnet (Claude Sonnet)
#   - openai/gpt-4-turbo (GPT-4 Turbo)
# Default: google/gemini-3-flash-preview
# Where to set: Convex (production), .env.local (dev)
# Used by: convex/aiGeneration.ts, convex/lab.ts, convex/iqc.ts, convex/evals/runner.ts
AI_MODEL=google/gemini-3-flash-preview

# Google AI API Key (for embeddings)
# Get from: https://aistudio.google.com/app/apikey
# Where to set: Convex (production), .env.local (dev)
# Used by: convex/embeddings.ts, convex/health.ts
# Note: This is separate from OPENROUTER_API_KEY - embeddings use Google AI directly
GOOGLE_AI_API_KEY=AIza...

# Application URL for redirects and links
# Where to set: Convex (production), .env.local (dev)
NEXT_PUBLIC_APP_URL=https://www.scry.study

# ------------------------------------------------------------------------------
# LLM OBSERVABILITY (Langfuse)
# ------------------------------------------------------------------------------

# Langfuse API Keys
# Get from: https://cloud.langfuse.com → Settings → API Keys
# Where to set: Convex (production), .env.local (dev)
# Used by: convex/lib/langfuse.ts, convex/lib/prompts.ts
LANGFUSE_SECRET_KEY=sk-lf-...
LANGFUSE_PUBLIC_KEY=pk-lf-...

# Langfuse Host URL
# Options:
#   - https://us.cloud.langfuse.com (US cloud - recommended for US users)
#   - https://cloud.langfuse.com (EU cloud - default)
#   - Your self-hosted instance URL
# IMPORTANT: Must match where your prompts are configured!
# Where to set: Convex (production), .env.local (dev)
LANGFUSE_HOST=https://us.cloud.langfuse.com

# ------------------------------------------------------------------------------
# OPTIONAL / ADMIN
# ------------------------------------------------------------------------------

# Admin emails for running migrations (comma-separated)
# Example: ADMIN_EMAILS=admin@example.com,ops@example.com
# Where to set: Convex (production), .env.local (dev)
ADMIN_EMAILS=your-admin-email@example.com
